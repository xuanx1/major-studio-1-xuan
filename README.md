# major-studio-1-xuan
![sketches-xuan](https://github.com/user-attachments/assets/7c313a2c-dd8d-408b-bdc4-d6d87b04497d)
1 “In Your Face” Search Bar  
When I was browsing and random generating search results through the API Query Discovery Tool, I realised that while the data is available in abundance, a robust classification or filtering system (and even GUI) is lacking for the users searching for relevant information – as I receive ample amount of irrelevant results or results that are too highly sophisticated which do not allow the average user to understand their contents. 
In line with SI’s requirements about addressing the accessibility of this engine, I figured it is important to incorporate the use of layman terms, tagged to their respective results, so when simple keywords are keyed in by the general users, they will yield the same, relevant result entered by a researcher using technical terms.
Hence, through the use of Word Cloud visualisation, the “In Your Face” Search Bar was conceptualised to illustrate an all-in-one widget that searches the database and filters at once as it matches the technical terms and the layman’s keywords they are tagged to. This is to assure users that they are in control of the results they yield and this widget is less likely to produce irrelevant search results.


![sketches-xuan2](https://github.com/user-attachments/assets/49cdc789-7a73-47d5-bc3d-c81413ecb634)
2 “Microscope” Index
Regarding the exhibiting data and documents related to NMNH - Vertebrate Zoology - Fishes Division and NMNH - Botany Dept, rather than just showing typical details like species, origins and pictures which is what is expected, but requires viewers to conduct their own further internet search to understand the technical terms or unfamiliar sounding locations in the descriptions they have just read.  
Alternatively, we can communicate this information in a more effectively manner through this “Microscope” concept. Zooming in information like satellite imaging or microscope as a visualisation of narrowing search results through interactive gestures, starting from the more general factors like their location of discovery or habitat before checking the more intricate filters like species name. 
In the contexts of NMNH - Vertebrate Zoology - Fishes Division and NMNH - Botany Dept there will be a slight difference when it comes to the type of information to be displayed for them to be effective and relevant. For example, for the Fishes there might a necessity to show the depths of the oceans they come from, whereas for Botany, it is sufficient to show its location. And the data these groups are time sensitive are they are affected by seasons and time of the year – which might eventually be reflected as a dynamic description page of their own type and species.


![SEA OF LIFE](https://github.com/user-attachments/assets/d5d5b817-454e-4d44-8c05-cacf8b3e5e67)
3 "SEA OF LIFE"
Focusing on attempting to visualise the Fish database for ease of access, I realise a good option to depict various species in their natural habitat might be to differentiate the depths they live in. Hence, the entire search UI will be based on a cross section visualisation from the beaches down to the depths of mariana trench. It allows the graphic to give viewers an idea of the context of the homes of respective species at a glance. CLicking on a fish /a set of fishes will direct the user to a dedicated page with details about them.
